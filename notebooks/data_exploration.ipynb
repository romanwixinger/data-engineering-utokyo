{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b2ba97",
   "metadata": {},
   "source": [
    "# Data exploration for joining all data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c611ee33",
   "metadata": {},
   "source": [
    "In this notebook we develop the functions for retrieving the tables, preparing them for the join, and then combining them based on the timestamp. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f28370",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb4a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import collections\n",
    "from abc import abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6deb4d2",
   "metadata": {},
   "source": [
    "## Sources\n",
    "In the following section we construct the methods to read the different csv files and convert them to flat tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2723925",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49f147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Helper():\n",
    "    \n",
    "    @classmethod\n",
    "    def timestamp_to_datetimes(cls, df: pd.DataFrame): \n",
    "        \"\"\" Takes a pandas dataframe with a timestamp column (int) and also adds date datetime, datetime_ms, datetime_μs. \n",
    "        \"\"\"\n",
    "        # Conversion functions\n",
    "        conversion_to_datetime_μs = lambda x: datetime.datetime.fromtimestamp(x/1000000000).strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "        conversion_to_datetime_ms = lambda x: datetime.datetime.fromtimestamp(x/1000000000).strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
    "        conversion_to_datetime = lambda x: datetime.datetime.fromtimestamp(x/1000000000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Apply conversions\n",
    "        df[\"datetime_μs\"] = df[\"timestamp\"].apply(conversion_to_datetime_μs)\n",
    "        df[\"datetime_ms\"] = df[\"timestamp\"].apply(conversion_to_datetime_ms)\n",
    "        df[\"datetime\"] = df[\"timestamp\"].apply(conversion_to_datetime)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6932467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recorder(object): \n",
    "    \"\"\" Base class for mapping a csv file to a pandas dataframe in real-time when it changes. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filepath: str): \n",
    "        # Settings\n",
    "        self.filepath = filepath\n",
    "        \n",
    "        # Tracking\n",
    "        self.read_data_lines = 0\n",
    "        self.read_metadata_lines = 0\n",
    "        self.last_updated = 0\n",
    "        self.data_last_updated = 0\n",
    "        self.metadata_last_updated = 0\n",
    "        \n",
    "        # Dataframes \n",
    "        self._table_df = None     # Data x Metadata\n",
    "        self._data_df = None      # Data\n",
    "        self._metadata_df = None  # Metadata\n",
    "\n",
    "    def get_table(self) -> pd.DataFrame: \n",
    "        self._update()\n",
    "        self.last_updated = self._get_mod_time()\n",
    "        return self._table_df\n",
    "    \n",
    "    def get_data(self) -> pd.DataFrame: \n",
    "        self._update_data()\n",
    "        self.data_last_updated = self._get_mod_time()\n",
    "        return self._data_df\n",
    "    \n",
    "    def get_metadata(self) -> pd.DataFrame: \n",
    "        self._update_metadata()\n",
    "        self.metadata_last_updated = self._get_mod_time()\n",
    "        self.metadata_columns = list(self._metadata_df.columns)\n",
    "        return self._metadata_df\n",
    "    \n",
    "    def table_is_up_to_date(self) -> bool: \n",
    "        return self.last_updated == self._get_mod_time()\n",
    "    \n",
    "    def data_is_up_to_date(self) -> bool: \n",
    "        return self.data_last_updated == self._get_mod_time()\n",
    "    \n",
    "    def metadata_is_up_to_date(self) -> bool: \n",
    "        return self.metadata_last_updated == self._get_mod_time()\n",
    "    \n",
    "    def _update(self): \n",
    "        if self.table_is_up_to_date(): \n",
    "            return \n",
    "        data_df = self.get_data()\n",
    "        metadata_df = self.get_metadata()\n",
    "        self._table_df = self._data_df.merge(self._metadata_df, how='cross') if self._metadata_df is not None else self._data_df\n",
    "        self._harmonize_time()\n",
    "        self._table_df = self._table_df.sort_values(by=\"timestamp\")\n",
    "        self.last_updated = self._get_mod_time()\n",
    "        \n",
    "    def _get_mod_time(self): \n",
    "        return time.ctime(os.path.getmtime(self.filepath))\n",
    "        \n",
    "    @abstractmethod\n",
    "    def _update_data(self):\n",
    "        \"\"\" Updates self.data_df and self.data_last_updated incrementally. \n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _update_metadata(self): \n",
    "        \"\"\" Updates self.metadata_df and self.metadata_last_updated. \n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _harmonize_time(self): \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a24aa5",
   "metadata": {},
   "source": [
    "### SSD2 Data\n",
    "Data from the WE7000 DAQ for the SSD2. The PMT current from the MOT will be obtained like this in our next experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a08c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecorderSSD(Recorder): \n",
    "    \"\"\" Class for data engineering of the SSD2 data. \"\"\"\n",
    "\n",
    "    def __init__(self, filepath: str):\n",
    "        super(RecorderSSD, self).__init__(filepath)\n",
    "\n",
    "    def _update_data(self): \n",
    "         self._data_df = pd.read_csv(filepath_or_buffer=self.filepath, \n",
    "                                 skiprows=37, \n",
    "                                 header=0, \n",
    "                                 names=[\"TraceName\", \"Time_x\", \"PulseHeight\"])\n",
    "        \n",
    "    def _update_metadata(self): \n",
    "        with open(self.filepath, newline='') as f:\n",
    "            reader = csv.reader(f)\n",
    "            metadata = list(reader)[:38]\n",
    "            metadata =  metadata[:3] +  metadata[4:]\n",
    "            columns = [line[0] for line in metadata]\n",
    "            row = [line[1] for line in metadata]\n",
    "            self._metadata_df = pd.DataFrame(data=[row], columns=columns)\n",
    "                \n",
    "    def _harmonize_time(self): \n",
    "        \"\"\" Convert the relative time and start time to the real time. \"\"\"\n",
    "        \n",
    "        def harmonize_table(df: pd.DataFrame) -> pd.DataFrame: \n",
    "            # Start time\n",
    "            helper_df = pd.DataFrame()\n",
    "            helper_df[\"start_datetime_str\"] = df[\"//StartDate\"].apply(lambda s: s.replace(\"/\", \"-\")) + \" \" + df[\"//StartTime\"]\n",
    "            helper_df[\"start_datetime\"] = pd.to_datetime(helper_df[\"start_datetime_str\"]) \n",
    "\n",
    "            # Conversion parameter: Time_x * rel_time_to_ns = rel. time in ns\n",
    "            time_resolution = df['//TimeResolution'][0]\n",
    "            rel_time_to_ns = {\n",
    "                '1.000000e-009': 1e-0,\n",
    "                '1.000000e-006': 1e+3,\n",
    "                '1.000000e-003': 1e+6\n",
    "            }[time_resolution]\n",
    "\n",
    "            # Real time\n",
    "            helper_df[\"relative_time_ns\"] = df[\"Time_x\"] * rel_time_to_ns\n",
    "            helper_df[\"start_ns\"] = helper_df.start_datetime.values.astype(np.int64)\n",
    "            helper_df[\"timestamp\"] = helper_df[\"start_ns\"] + helper_df[\"relative_time_ns\"]\n",
    "\n",
    "            # Add datetimes\n",
    "            df[\"timestamp\"] = helper_df[\"timestamp\"]\n",
    "            Helper.timestamp_to_datetimes(df)\n",
    "            return df\n",
    "        \n",
    "        self._table_df = harmonize_table(self._table_df)\n",
    "        self._data_df = self._table_df[self._data_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee5d8ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TraceName</th>\n",
       "      <th>Time_x</th>\n",
       "      <th>PulseHeight</th>\n",
       "      <th>Model</th>\n",
       "      <th>BlockNumber</th>\n",
       "      <th>BlockSize</th>\n",
       "      <th>VUnit</th>\n",
       "      <th>HResolution</th>\n",
       "      <th>HUnit</th>\n",
       "      <th>Date</th>\n",
       "      <th>...</th>\n",
       "      <th>//StopSource</th>\n",
       "      <th>//TimeResolution</th>\n",
       "      <th>//TimeStamp</th>\n",
       "      <th>//RealTime</th>\n",
       "      <th>//LiveTime</th>\n",
       "      <th>//DeadTime(%)</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datetime_μs</th>\n",
       "      <th>datetime_ms</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>553786</td>\n",
       "      <td>2463</td>\n",
       "      <td>WE7562</td>\n",
       "      <td>1</td>\n",
       "      <td>15262</td>\n",
       "      <td>cnt</td>\n",
       "      <td>1.000000e+000</td>\n",
       "      <td>?</td>\n",
       "      <td>2022/03/14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-006</td>\n",
       "      <td>Peak</td>\n",
       "      <td>7.136569e+003</td>\n",
       "      <td>7.136410e+003</td>\n",
       "      <td>2.233544e-003</td>\n",
       "      <td>1.647252e+18</td>\n",
       "      <td>2022-03-14 19:07:54.553786</td>\n",
       "      <td>2022-03-14 19:07:54.553</td>\n",
       "      <td>2022-03-14 19:07:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>865236</td>\n",
       "      <td>2855</td>\n",
       "      <td>WE7562</td>\n",
       "      <td>1</td>\n",
       "      <td>15262</td>\n",
       "      <td>cnt</td>\n",
       "      <td>1.000000e+000</td>\n",
       "      <td>?</td>\n",
       "      <td>2022/03/14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-006</td>\n",
       "      <td>Peak</td>\n",
       "      <td>7.136569e+003</td>\n",
       "      <td>7.136410e+003</td>\n",
       "      <td>2.233544e-003</td>\n",
       "      <td>1.647252e+18</td>\n",
       "      <td>2022-03-14 19:07:54.865236</td>\n",
       "      <td>2022-03-14 19:07:54.865</td>\n",
       "      <td>2022-03-14 19:07:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2486115</td>\n",
       "      <td>2516</td>\n",
       "      <td>WE7562</td>\n",
       "      <td>1</td>\n",
       "      <td>15262</td>\n",
       "      <td>cnt</td>\n",
       "      <td>1.000000e+000</td>\n",
       "      <td>?</td>\n",
       "      <td>2022/03/14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-006</td>\n",
       "      <td>Peak</td>\n",
       "      <td>7.136569e+003</td>\n",
       "      <td>7.136410e+003</td>\n",
       "      <td>2.233544e-003</td>\n",
       "      <td>1.647252e+18</td>\n",
       "      <td>2022-03-14 19:07:56.486115</td>\n",
       "      <td>2022-03-14 19:07:56.486</td>\n",
       "      <td>2022-03-14 19:07:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2628986</td>\n",
       "      <td>2527</td>\n",
       "      <td>WE7562</td>\n",
       "      <td>1</td>\n",
       "      <td>15262</td>\n",
       "      <td>cnt</td>\n",
       "      <td>1.000000e+000</td>\n",
       "      <td>?</td>\n",
       "      <td>2022/03/14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-006</td>\n",
       "      <td>Peak</td>\n",
       "      <td>7.136569e+003</td>\n",
       "      <td>7.136410e+003</td>\n",
       "      <td>2.233544e-003</td>\n",
       "      <td>1.647252e+18</td>\n",
       "      <td>2022-03-14 19:07:56.628986</td>\n",
       "      <td>2022-03-14 19:07:56.628</td>\n",
       "      <td>2022-03-14 19:07:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2650471</td>\n",
       "      <td>2456</td>\n",
       "      <td>WE7562</td>\n",
       "      <td>1</td>\n",
       "      <td>15262</td>\n",
       "      <td>cnt</td>\n",
       "      <td>1.000000e+000</td>\n",
       "      <td>?</td>\n",
       "      <td>2022/03/14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-006</td>\n",
       "      <td>Peak</td>\n",
       "      <td>7.136569e+003</td>\n",
       "      <td>7.136410e+003</td>\n",
       "      <td>2.233544e-003</td>\n",
       "      <td>1.647252e+18</td>\n",
       "      <td>2022-03-14 19:07:56.650471</td>\n",
       "      <td>2022-03-14 19:07:56.650</td>\n",
       "      <td>2022-03-14 19:07:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15257</th>\n",
       "      <td>15257</td>\n",
       "      <td>7133087349</td>\n",
       "      <td>2993</td>\n",
       "      <td>WE7562</td>\n",
       "      <td>1</td>\n",
       "      <td>15262</td>\n",
       "      <td>cnt</td>\n",
       "      <td>1.000000e+000</td>\n",
       "      <td>?</td>\n",
       "      <td>2022/03/14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-006</td>\n",
       "      <td>Peak</td>\n",
       "      <td>7.136569e+003</td>\n",
       "      <td>7.136410e+003</td>\n",
       "      <td>2.233544e-003</td>\n",
       "      <td>1.647260e+18</td>\n",
       "      <td>2022-03-14 21:06:47.087349</td>\n",
       "      <td>2022-03-14 21:06:47.087</td>\n",
       "      <td>2022-03-14 21:06:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15258</th>\n",
       "      <td>15258</td>\n",
       "      <td>7133923984</td>\n",
       "      <td>2465</td>\n",
       "      <td>WE7562</td>\n",
       "      <td>1</td>\n",
       "      <td>15262</td>\n",
       "      <td>cnt</td>\n",
       "      <td>1.000000e+000</td>\n",
       "      <td>?</td>\n",
       "      <td>2022/03/14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-006</td>\n",
       "      <td>Peak</td>\n",
       "      <td>7.136569e+003</td>\n",
       "      <td>7.136410e+003</td>\n",
       "      <td>2.233544e-003</td>\n",
       "      <td>1.647260e+18</td>\n",
       "      <td>2022-03-14 21:06:47.923984</td>\n",
       "      <td>2022-03-14 21:06:47.923</td>\n",
       "      <td>2022-03-14 21:06:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15259</th>\n",
       "      <td>15259</td>\n",
       "      <td>7134604904</td>\n",
       "      <td>3007</td>\n",
       "      <td>WE7562</td>\n",
       "      <td>1</td>\n",
       "      <td>15262</td>\n",
       "      <td>cnt</td>\n",
       "      <td>1.000000e+000</td>\n",
       "      <td>?</td>\n",
       "      <td>2022/03/14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-006</td>\n",
       "      <td>Peak</td>\n",
       "      <td>7.136569e+003</td>\n",
       "      <td>7.136410e+003</td>\n",
       "      <td>2.233544e-003</td>\n",
       "      <td>1.647260e+18</td>\n",
       "      <td>2022-03-14 21:06:48.604904</td>\n",
       "      <td>2022-03-14 21:06:48.604</td>\n",
       "      <td>2022-03-14 21:06:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15260</th>\n",
       "      <td>15260</td>\n",
       "      <td>7135583418</td>\n",
       "      <td>2726</td>\n",
       "      <td>WE7562</td>\n",
       "      <td>1</td>\n",
       "      <td>15262</td>\n",
       "      <td>cnt</td>\n",
       "      <td>1.000000e+000</td>\n",
       "      <td>?</td>\n",
       "      <td>2022/03/14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-006</td>\n",
       "      <td>Peak</td>\n",
       "      <td>7.136569e+003</td>\n",
       "      <td>7.136410e+003</td>\n",
       "      <td>2.233544e-003</td>\n",
       "      <td>1.647260e+18</td>\n",
       "      <td>2022-03-14 21:06:49.583418</td>\n",
       "      <td>2022-03-14 21:06:49.583</td>\n",
       "      <td>2022-03-14 21:06:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15261</th>\n",
       "      <td>15261</td>\n",
       "      <td>7136399306</td>\n",
       "      <td>2408</td>\n",
       "      <td>WE7562</td>\n",
       "      <td>1</td>\n",
       "      <td>15262</td>\n",
       "      <td>cnt</td>\n",
       "      <td>1.000000e+000</td>\n",
       "      <td>?</td>\n",
       "      <td>2022/03/14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000e-006</td>\n",
       "      <td>Peak</td>\n",
       "      <td>7.136569e+003</td>\n",
       "      <td>7.136410e+003</td>\n",
       "      <td>2.233544e-003</td>\n",
       "      <td>1.647260e+18</td>\n",
       "      <td>2022-03-14 21:06:50.399306</td>\n",
       "      <td>2022-03-14 21:06:50.399</td>\n",
       "      <td>2022-03-14 21:06:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15262 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TraceName      Time_x  PulseHeight   Model BlockNumber  \\\n",
       "0              0      553786         2463  WE7562           1   \n",
       "1              1      865236         2855  WE7562           1   \n",
       "2              2     2486115         2516  WE7562           1   \n",
       "3              3     2628986         2527  WE7562           1   \n",
       "4              4     2650471         2456  WE7562           1   \n",
       "...          ...         ...          ...     ...         ...   \n",
       "15257      15257  7133087349         2993  WE7562           1   \n",
       "15258      15258  7133923984         2465  WE7562           1   \n",
       "15259      15259  7134604904         3007  WE7562           1   \n",
       "15260      15260  7135583418         2726  WE7562           1   \n",
       "15261      15261  7136399306         2408  WE7562           1   \n",
       "\n",
       "                 BlockSize VUnit    HResolution HUnit        Date  ...  \\\n",
       "0      15262                 cnt  1.000000e+000     ?  2022/03/14  ...   \n",
       "1      15262                 cnt  1.000000e+000     ?  2022/03/14  ...   \n",
       "2      15262                 cnt  1.000000e+000     ?  2022/03/14  ...   \n",
       "3      15262                 cnt  1.000000e+000     ?  2022/03/14  ...   \n",
       "4      15262                 cnt  1.000000e+000     ?  2022/03/14  ...   \n",
       "...                    ...   ...            ...   ...         ...  ...   \n",
       "15257  15262                 cnt  1.000000e+000     ?  2022/03/14  ...   \n",
       "15258  15262                 cnt  1.000000e+000     ?  2022/03/14  ...   \n",
       "15259  15262                 cnt  1.000000e+000     ?  2022/03/14  ...   \n",
       "15260  15262                 cnt  1.000000e+000     ?  2022/03/14  ...   \n",
       "15261  15262                 cnt  1.000000e+000     ?  2022/03/14  ...   \n",
       "\n",
       "      //StopSource //TimeResolution //TimeStamp     //RealTime     //LiveTime  \\\n",
       "0             None    1.000000e-006        Peak  7.136569e+003  7.136410e+003   \n",
       "1             None    1.000000e-006        Peak  7.136569e+003  7.136410e+003   \n",
       "2             None    1.000000e-006        Peak  7.136569e+003  7.136410e+003   \n",
       "3             None    1.000000e-006        Peak  7.136569e+003  7.136410e+003   \n",
       "4             None    1.000000e-006        Peak  7.136569e+003  7.136410e+003   \n",
       "...            ...              ...         ...            ...            ...   \n",
       "15257         None    1.000000e-006        Peak  7.136569e+003  7.136410e+003   \n",
       "15258         None    1.000000e-006        Peak  7.136569e+003  7.136410e+003   \n",
       "15259         None    1.000000e-006        Peak  7.136569e+003  7.136410e+003   \n",
       "15260         None    1.000000e-006        Peak  7.136569e+003  7.136410e+003   \n",
       "15261         None    1.000000e-006        Peak  7.136569e+003  7.136410e+003   \n",
       "\n",
       "       //DeadTime(%)     timestamp                 datetime_μs  \\\n",
       "0      2.233544e-003  1.647252e+18  2022-03-14 19:07:54.553786   \n",
       "1      2.233544e-003  1.647252e+18  2022-03-14 19:07:54.865236   \n",
       "2      2.233544e-003  1.647252e+18  2022-03-14 19:07:56.486115   \n",
       "3      2.233544e-003  1.647252e+18  2022-03-14 19:07:56.628986   \n",
       "4      2.233544e-003  1.647252e+18  2022-03-14 19:07:56.650471   \n",
       "...              ...           ...                         ...   \n",
       "15257  2.233544e-003  1.647260e+18  2022-03-14 21:06:47.087349   \n",
       "15258  2.233544e-003  1.647260e+18  2022-03-14 21:06:47.923984   \n",
       "15259  2.233544e-003  1.647260e+18  2022-03-14 21:06:48.604904   \n",
       "15260  2.233544e-003  1.647260e+18  2022-03-14 21:06:49.583418   \n",
       "15261  2.233544e-003  1.647260e+18  2022-03-14 21:06:50.399306   \n",
       "\n",
       "                   datetime_ms             datetime  \n",
       "0      2022-03-14 19:07:54.553  2022-03-14 19:07:54  \n",
       "1      2022-03-14 19:07:54.865  2022-03-14 19:07:54  \n",
       "2      2022-03-14 19:07:56.486  2022-03-14 19:07:56  \n",
       "3      2022-03-14 19:07:56.628  2022-03-14 19:07:56  \n",
       "4      2022-03-14 19:07:56.650  2022-03-14 19:07:56  \n",
       "...                        ...                  ...  \n",
       "15257  2022-03-14 21:06:47.087  2022-03-14 21:06:47  \n",
       "15258  2022-03-14 21:06:47.923  2022-03-14 21:06:47  \n",
       "15259  2022-03-14 21:06:48.604  2022-03-14 21:06:48  \n",
       "15260  2022-03-14 21:06:49.583  2022-03-14 21:06:49  \n",
       "15261  2022-03-14 21:06:50.399  2022-03-14 21:06:50  \n",
       "\n",
       "[15262 rows x 44 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorderSDD = RecorderSSD(location+\"-20220314-100806-Slot1-In2.csv\")\n",
    "ssd_df = recorderSDD.get_table()\n",
    "ssd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d1d455",
   "metadata": {},
   "source": [
    "### SSD Histogram representation\n",
    "A very useful representation of the SSD data is when we group by time (primary key) and then count the number of pulses with a certain hight. The columns then correspond to voltage ranges in 12-bit (0, 1, 2, 3, ..., 4094, 4095) encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a54251",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSDRepresentation(): \n",
    "    \n",
    "    @classmethod\n",
    "    def get_hist_rep(cls, ssd_df: pd.DataFrame) -> pd.DataFrame: \n",
    "        nr_of_channels = ssd_df[\"//Gain\"][0]\n",
    "        \n",
    "        # Groupby timestamp and PulseHeight (channel)\n",
    "        grouped = ssd_df.groupby(by=[\"datetime\", \"PulseHeight\"])\n",
    "        df = grouped.agg({\"TraceName\": 'count'}).rename({\"TraceName\": \"PulseCount\"}, axis=1)\n",
    "        df = df.unstack(level='PulseHeight').fillna(0, downcast=\"infer\")\n",
    "        \n",
    "        # Fix column names\n",
    "        df.columns = df.columns.to_flat_index()\n",
    "        df.columns = [str(col[1]) for col in df.columns.values]\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    @classmethod\n",
    "    def get_fully_aggregated_hist_rep(cls, ssd_df: pd.DataFrame) -> pd.DataFrame: \n",
    "        df = cls.get_hist_rep(ssd_df) \n",
    "        df_sum = df.sum()\n",
    "        df = pd.DataFrame(data=[df_sum.values], columns=df_sum.index.values)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_hist_df = SSDRepresentation.get_hist_rep(ssd_df)\n",
    "ssd_hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7417399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_full_agg_hist_df = SSDRepresentation.get_fully_aggregated_hist_rep(ssd_df)\n",
    "ssd_full_agg_hist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f860b",
   "metadata": {},
   "source": [
    "### PMT Data\n",
    "In the table, we have the following columns. \n",
    "- No. : Frame number of CMOS camera\n",
    "- Time: When the frame is obtained\n",
    "- PMT Current: Current from photomultiplier at the time the frame obtained\n",
    "- ROI Sum: The sum of signal values in ROI\n",
    "- Coil (1:ON 0:ODD): The current of the coil at that time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8291eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMT(): \n",
    "    \n",
    "    @classmethod\n",
    "    def get_table(cls, filepath: str=location+\"all_data.csv\"): \n",
    "        df = pd.read_csv(filepath_or_buffer=filepath)\n",
    "        df.rename({\"Unnamed: 5\": \"a\"}, axis=\"columns\", inplace=True)\n",
    "        df = df.drop([\"a\"], axis=1)\n",
    "        cls._harmonize_time(df)\n",
    "        df = df.sort_values(by=\"timestamp\")\n",
    "        return df\n",
    "    \n",
    "    @classmethod\n",
    "    def _harmonize_time(cls, df: pd.DataFrame): \n",
    "        df[\"datetime_μs\"] = df[\"Time\"].apply(lambda s: s+\"000\")\n",
    "        df[\"datetime_ms\"] = df[\"Time\"]\n",
    "        df[\"datetime\"] = df[\"Time\"].apply(lambda s: s[:-4])\n",
    "        df[\"timestamp\"] = df[\"Time\"].apply(pd.Timestamp).values.astype(np.int64)\n",
    "        return \n",
    "    \n",
    "pmt_df = PMT.get_table()\n",
    "pmt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89cb708",
   "metadata": {},
   "source": [
    "### Coil Log\n",
    "The current of the MOT coil is controlled by a relay switch. This text file is the log of the relay switch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c364f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coil(): \n",
    "    \n",
    "    @classmethod\n",
    "    def get_table(cls, filepath: str=location+\"coil_log.txt\"): \n",
    "        df = pd.read_csv(filepath_or_buffer=filepath, delimiter=\"\t\")\n",
    "        cls._harmonize_time(df)\n",
    "        df = df.sort_values(by=\"timestamp\")\n",
    "        return df\n",
    "    \n",
    "    @classmethod\n",
    "    def _harmonize_time(cls, df: pd.DataFrame): \n",
    "        df[\"datetime_μs\"] = df[\"Time\"].apply(lambda s: s+\"000\")\n",
    "        df[\"datetime_ms\"] = df[\"Time\"]\n",
    "        df[\"datetime\"] = df[\"Time\"].apply(lambda s: s[:-4])\n",
    "        df[\"timestamp\"] = df[\"Time\"].apply(pd.Timestamp).values.astype(np.int64)\n",
    "        return \n",
    "\n",
    "coil_table = Coil.get_table()\n",
    "coil_table "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ba9c1",
   "metadata": {},
   "source": [
    "### Heater Log\n",
    "Log of the IR heater output percentage for target heating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450cc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Heater(): \n",
    "    \"\"\" Class for data engineering of the heater data. \"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def get_table(cls, filepath: str=location+\"HeaterLog_20220314_100740_00001.csv\", with_metadata: bool=False): \n",
    "        \"\"\" Load full table, consisting of data and metadata in a flat format. \"\"\"\n",
    "        data_df = cls._get_data(filepath)\n",
    "        metadata_df = cls._get_metadata(filepath)\n",
    "        df = data_df.merge(metadata_df, how='cross')\n",
    "        cls._harmonize_time(df)\n",
    "        if with_metadata: \n",
    "            return df\n",
    "        return df[[col for col in df.columns if col not in metadata_df.columns]]    \n",
    "    \n",
    "    @classmethod\n",
    "    def _get_data(cls, filepath: str=location+\"HeaterLog_20220314_100740_00001.csv\") -> pd.DataFrame: \n",
    "        df = pd.read_csv(filepath_or_buffer=filepath, \n",
    "                                 skiprows=6, \n",
    "                                 header=0, \n",
    "                                 names=[\"Date\", \"Time\", \"Unknown\", \"TargetPercentage\", \"MeasuredPercentage\"],\n",
    "                                 encoding=\"cp932\")\n",
    "        cls._harmonize_time(df)\n",
    "        df = df.sort_values(by=\"timestamp\")\n",
    "        return df\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_metadata(cls, filepath: str=location+\"HeaterLog_20220314_100740_00001.csv\"): \n",
    "        with open(filepath, newline='', encoding=\"cp932\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            metadata_list = list(reader)[:6]\n",
    "            columns = [m[0] for m in metadata_list]\n",
    "            row = [metadata_list[i][1] for i in range(2)] +  [f\"{metadata_list[i][3]},{metadata_list[i][4]}\" for i in range(2, 6)]\n",
    "            df = pd.DataFrame(data=[row], columns=columns)\n",
    "            return df\n",
    "    \n",
    "    @classmethod\n",
    "    def _harmonize_time(cls, df: pd.DataFrame) -> pd.DataFrame: \n",
    "        df[\"datetime\"] = df[\"Date\"].apply(lambda s: s.replace(\"/\", \"-\")) + \" \" + df[\"Time\"]\n",
    "        df[\"datetime_μs\"] = df[\"datetime\"].apply(lambda s: s+\".000000\")\n",
    "        df[\"datetime_ms\"] = df[\"datetime\"].apply(lambda s: s+\".000\")\n",
    "        df[\"timestamp\"] = df[\"datetime_ms\"].apply(pd.Timestamp).values.astype(np.int64)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ade9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heater_df = Heater.get_table(with_metadata=False)\n",
    "heater_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908f3b1",
   "metadata": {},
   "source": [
    "### Ion Beam Control\n",
    "Log of the Fr ion source. First day of experiment, right after the end of primary beam check, just starting the Fr ion extraction. The column \"FC\" is the current from either one of the faraday cups, or the sum of both.\n",
    "The columns \"Center\" and \"Surrounding\" are the voltages applied to the mechanical relay switches that connects the faraday cups to the picoammeter. For example, if \"Center\" = 24 and \"Surrounding\" = 0, the value at \"FC\" is the current observed on FC Center in nA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9fe746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class IonBeamControl(): \n",
    "    \n",
    "    @classmethod\n",
    "    def get_table(cls, filepath: str=location+\"IonBeamControl1.5_DESKTOP-8ICG2TJ_20220314_114132.csv\"): \n",
    "        df = pd.read_csv(filepath_or_buffer=filepath)\n",
    "        cls._harmonize_time(df)\n",
    "        df = df.sort_values(by=\"timestamp\")\n",
    "        return df\n",
    "    \n",
    "    @classmethod\n",
    "    def _harmonize_time(cls, df: pd.DataFrame) -> pd.DataFrame: \n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "        df[\"datetime_μs\"] = df[\"Timestamp\"].apply(lambda s: s+\".000000\")\n",
    "        df[\"datetime_ms\"] = df[\"Timestamp\"].apply(lambda s: s+\".000\")\n",
    "        df[\"timestamp\"] = df[\"datetime\"].values.astype(np.int64)\n",
    "        \n",
    "ion_beam_control_df = IonBeamControl.get_table()\n",
    "ion_beam_control_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0227daa4",
   "metadata": {},
   "source": [
    "### Gauge Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44427be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gauge(): \n",
    "    \n",
    "    @classmethod\n",
    "    def get_table(cls, filepath: str=location+\"TPG256GaugeMonitor_Single_DESKTOP-BEF5FI4_20220312_203214.csv\"): \n",
    "        df = pd.read_csv(filepath_or_buffer=filepath)\n",
    "        cls._harmonize_time(df)\n",
    "        df = df.sort_values(by=\"timestamp\")\n",
    "        return df\n",
    "    \n",
    "    @classmethod\n",
    "    def _harmonize_time(cls, df: pd.DataFrame): \n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "        df[\"datetime_μs\"] = df[\"Timestamp\"].apply(lambda s: s+\".000000\")\n",
    "        df[\"datetime_ms\"] = df[\"Timestamp\"].apply(lambda s: s+\".000\")\n",
    "        df[\"timestamp\"] = df[\"datetime\"].values.astype(np.int64)\n",
    "        return df\n",
    "\n",
    "gauge_df = Gauge.get_table()\n",
    "gauge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0112d5c6",
   "metadata": {},
   "source": [
    "### Laser data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Laser(): \n",
    "    \n",
    "    @classmethod\n",
    "    def get_table(cls, filepath: str=location+\"15.03.2022, 21.30, 384.22817013 THz.lta\", with_metadata: bool=False): \n",
    "        \"\"\" Load full table, consisting of data and metadata in a flat format. \"\"\"\n",
    "        data_df = cls._get_data(filepath)\n",
    "        metadata_df = cls._get_metadata(filepath)\n",
    "        if not with_metadata: \n",
    "            metadata_df = metadata_df[[\"StartTime\"]]\n",
    "        df = data_df.merge(metadata_df, how='cross')\n",
    "        cls._harmonize_time(df)\n",
    "        df = df.sort_values(by=\"timestamp\")\n",
    "        if with_metadata: \n",
    "            return df\n",
    "        else:\n",
    "            return df[[col for col in df.columns if col not in metadata_df.columns]]     \n",
    "    \n",
    "    @classmethod\n",
    "    def _get_data(cls, filepath: str=location+\"15.03.2022, 21.30, 384.22817013 THz.lta\") -> pd.DataFrame:\n",
    "        \"\"\" Loads the data and makes sure that each row has all laser measurements by aggregating rows. \"\"\"\n",
    "        original_df = pd.read_csv(filepath_or_buffer=filepath, \n",
    "                                  skiprows=119,\n",
    "                                  delimiter=\"\t\")\n",
    "        \n",
    "        df = cls._aggregate_laser_rows(original_df)\n",
    "        return df\n",
    "        \n",
    "    @classmethod\n",
    "    def _aggregate_laser_rows(cls, original_df: pd.DataFrame): \n",
    "        \"\"\" Originally, one measurement of the six laser wavelengths is distributed over six rows. We aggregate \n",
    "            these rows into one row. The only tradeoff is that we have to approximate the time with the time\n",
    "            of the last measurement. \n",
    "        \"\"\"\n",
    "        \n",
    "        n = len(original_df.index)\n",
    "        \n",
    "        time_column = 'Time  [ms]'\n",
    "        laser_columns = original_df.columns[1:]\n",
    "        n_laser_columns = len(laser_columns)\n",
    "        \n",
    "        laser_column_lookup = {col: i for i, col in enumerate(laser_columns)}\n",
    "        data_lookup = collections.defaultdict(list)\n",
    "        row_lookup = {}\n",
    "        row_list = []\n",
    "        \n",
    "        for index, row in original_df.iterrows():\n",
    "            column_index = pd.Series.first_valid_index(row[1:])\n",
    "            row_lookup[column_index] = row[column_index]\n",
    "            # Count if all 6 lasers have been measured\n",
    "            if len(row_lookup) == 6:     \n",
    "                item = [row[time_column]] + [row_lookup[col] for col in laser_columns]\n",
    "                row_list.append(item)\n",
    "                row_lookup = {}\n",
    "\n",
    "        df = pd.DataFrame(data=row_list, columns=original_df.columns)\n",
    "        return df\n",
    "        \n",
    "    @classmethod\n",
    "    def _get_metadata(cls, filepath: str=location+\"15.03.2022, 21.30, 384.22817013 THz.lta\"): \n",
    "        with open(filepath, newline='', encoding=\"cp932\") as f:\n",
    "            reader = csv.reader(f, delimiter=\"\t\")\n",
    "            metadata_list = list(reader)[:119]\n",
    "            \n",
    "            # Title\n",
    "            title_column = [\"Title\"]\n",
    "            title_row = [metadata_list[0][0]]\n",
    "            \n",
    "            # General info\n",
    "            gi_columns = [m[0] for m in metadata_list[1:7]]\n",
    "            gi_rows = [cls._combine(m[1:]) for m in metadata_list[1:7]]\n",
    "            \n",
    "            # General settings\n",
    "            gs_columns = [m[0] for m in metadata_list[9:20]]\n",
    "            gs_rows = [cls._combine(m[1:]) for m in metadata_list[9:20]]\n",
    "\n",
    "            # Frames 1-6\n",
    "            frame_columns = (\n",
    "                [m[0] for m in metadata_list[22:36]]\n",
    "                + [m[0] for m in metadata_list[38:52]]\n",
    "                + [m[0] for m in metadata_list[54:68]]\n",
    "                + [m[0] for m in metadata_list[70:84]]\n",
    "                + [m[0] for m in metadata_list[86:100]]\n",
    "                + [m[0] for m in metadata_list[102:116]]\n",
    "            )\n",
    "            \n",
    "            frame_rows = (\n",
    "                [cls._combine(m[1:]) for m in metadata_list[22:36]]\n",
    "                + [cls._combine(m[1:]) for m in metadata_list[38:52]]\n",
    "                + [cls._combine(m[1:]) for m in metadata_list[54:68]]\n",
    "                + [cls._combine(m[1:]) for m in metadata_list[70:84]]\n",
    "                + [cls._combine(m[1:]) for m in metadata_list[86:100]]\n",
    "                + [cls._combine(m[1:]) for m in metadata_list[102:116]]\n",
    "            )\n",
    "            \n",
    "            columns = title_column + gi_columns + gs_columns + frame_columns\n",
    "            row = title_row + gi_rows + gs_rows + frame_rows\n",
    "            df = pd.DataFrame(data=[row], columns=columns)\n",
    "            return df                                    \n",
    "    \n",
    "    @classmethod\n",
    "    def _combine(cls, entries: list): \n",
    "        \"\"\" If entries has length 1, then it returns the entry. \n",
    "            Otherwise, it converts the list to a comma separated string. \n",
    "        \"\"\"\n",
    "        if len(entries) == 0: \n",
    "            return None\n",
    "        \n",
    "        if len(entries) == 1: \n",
    "            return entries[0]\n",
    "        \n",
    "        return \",\".join(entries)\n",
    "    \n",
    "    @classmethod\n",
    "    def _harmonize_time(cls, df: pd.DataFrame):\n",
    "\n",
    "        # Convert 15.03.2022, 08:46:39.387 to 15-03-2022 08:46:39.387\n",
    "        helper_df = pd.DataFrame()\n",
    "        helper_df[\"StartTime\"] = df[\"StartTime\"].apply(lambda s: s.replace(\",\", \"\").replace(\".\", \"-\", 2))\n",
    "        \n",
    "        # Calculate absolute time based on relative time\n",
    "        helper_df[\"start_datetime\"] = pd.to_datetime(helper_df[\"StartTime\"])\n",
    "        helper_df[\"start_timestamp\"] = helper_df[\"start_datetime\"].values.astype(np.int64)\n",
    "        helper_df[\"timestamp\"] = helper_df[\"start_timestamp\"] + df[\"Time  [ms]\"] * 1e3\n",
    "        \n",
    "        # Add datetimes\n",
    "        df[\"timestamp\"] = helper_df[\"timestamp\"]\n",
    "        Helper.timestamp_to_datetimes(df)\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c07877",
   "metadata": {},
   "outputs": [],
   "source": [
    "laser_df = Laser.get_table(with_metadata=False)\n",
    "laser_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901b56d",
   "metadata": {},
   "source": [
    "### Image data\n",
    "We have a folder which contains the picture data from the CMOS camera. A part of the pixels (region of interest, ROI) selected in advance is extracted. Each picture data is a csv file and records signals from each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image(): \n",
    "    \n",
    "    def get_array(filepath: str=location+\"cmos_000039.csv\"): \n",
    "        with open(filepath) as file_name:\n",
    "            return np.loadtxt(file_name, delimiter=\",\")\n",
    "        \n",
    "    def get_metadata(filepath: str=location+\"cmos_000039.csv\") -> pd.DataFrame: \n",
    "        \n",
    "        columns = [\"size\", \"ctime\"] # Size and creation time\n",
    "        row = [os.path.getsize(filepath), os.path.getctime(filepath)]\n",
    "        return pd.DataFrame(data=[row], columns=columns)\n",
    "        \n",
    "image_array = Image.get_array()\n",
    "image_table = Image.get_metadata()\n",
    "image_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c349e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf288465",
   "metadata": {},
   "source": [
    "## Joins\n",
    "For a refresher on joins, checkout this article: https://pandas.pydata.org/docs/user_guide/merging.html. Now our goal is to join the tables into a main table. We join on the timestamp and define the following rules: \n",
    "- We join on timestamp in seconds with an outer join.\n",
    "- As the values do not exactly match, we first sort the dataframes, such that we then can join on nearly-matching values with some threshold (https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.merge_asof.html). \n",
    "\n",
    "Problem: \n",
    "- As the sampling method varies a lot, we would lose a lot of data with this method. \n",
    "\n",
    "Solution A: \n",
    "- Treat some tables as parameters and settings, and some tables as measurements. Then we first sample the parameters and settings on level second, and then use a finer sampling for the measurements. \n",
    "- For this, we first find all unique times in seconds. Then we generate the rows for each unique second, taking the value if it exists or nan if not. \n",
    "- Last, we do an outer join on the time in seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a86ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Main(): \n",
    "\n",
    "    def limit_tables_to_timespan(dfs, start, stop): \n",
    "        \"\"\" Takes a list of dfs, only keeps the rows between start and stop time and returns the modified list. \n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def build_table(dfs: list, prefixes: list): \n",
    "        \"\"\" Concatenates the dataframes to a single dataframe, ignoring the indices. The names are used as prefixes of the\n",
    "            columns, such that we can have similar column names but still know from which df it came. \n",
    "        \"\"\"   \n",
    "          \n",
    "        # Add prefixes\n",
    "        dfs = [df.rename(columns={col: prefix+\"_\"+col for col in df.columns}) for df, prefix in zip(dfs, prefixes)]\n",
    "        \n",
    "        # Outer join \n",
    "        main_df = pd.concat(dfs, axis=1, join=\"outer\")\n",
    "        \n",
    "        return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d122624",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_table = Main.build_table(\n",
    "    dfs=[laser_df, gauge_df, ion_beam_control_df, heater_df, coil_table, pmt_df, ssd_df, ssd_hist_df],\n",
    "    prefixes=[\"laser\", \"gauge\", \"ion_beam_control\", \"heater\", \"coil\", \"pmt\", \"ssd\", \"ssd_hist\"]\n",
    ")\n",
    "main_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5673530",
   "metadata": {},
   "source": [
    "### Analysis \n",
    "In the following we want to test some simple analysis as proof of concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10897b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
